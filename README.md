# ğŸ“Š Credit Risk Classification with Decision Trees, Random Forest, and SVM

This repository contains the **Datamanz project** for credit risk classification on the German Credit dataset.  
We compare **Decision Trees**, **Random Forest**, and **Support Vector Machines (SVM)**, reporting metrics such as accuracy, sensitivity, specificity, PPV, ROC/AUC, and variable importance.  

---

## âœ¨ Project Objectives
- ğŸ” Perform **Exploratory Data Analysis (EDA)** to identify key patterns.  
- ğŸŒ³ Build and prune **Decision Trees** for interpretability.  
- ğŸŒ² Apply **Random Forest** for ensemble learning.  
- ğŸ¤– Train **Support Vector Machines (SVM)** for margin-based classification.  
- ğŸ“ˆ Evaluate models with **confusion matrices, metrics, and ROC curves**.  

---

## ğŸ“‚ Repository Structure

```bash
â”œâ”€â”€ data/                  # Dataset (German Credit)
â”œâ”€â”€ scripts/               # Modular R scripts for each step
â”œâ”€â”€ results/               # Outputs: confusion matrices, metrics, variable importance
â”œâ”€â”€ docs/                  # Plots and images for README
â”‚   â”œâ”€â”€ 1.JPG
â”‚   â”œâ”€â”€ 2.JPG
â”‚   â”œâ”€â”€ 3.JPG
â”‚   â””â”€â”€ 4.JPG
â”œâ”€â”€ Datamanz_CreditRisk.Rmd
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore

---

## ğŸ–¼ï¸ Key Visuals

### ğŸ” Exploratory Data Analysis
**Default Distribution by Job Type**  
![Job Type Distribution](docs/1.JPG)

**Correlation Matrix**  
![Correlation Matrix](docs/2.JPG)

---

### ğŸŒ³ Decision Tree
**Pruned Tree**  
![Pruned Tree](docs/3.JPG)

**Extracted Rules**  
![Extracted Rules](docs/4.JPG)

---

## ğŸ“Š Model Results

- ğŸŒ³ **Decision Tree**  
  - Accuracy: 67%  
  - Sensitivity: 45.45%  
  - Specificity: 80%  

- ğŸŒ² **Random Forest (base)**  
  - Accuracy: 74%  
  - Sensitivity: 59.09%  
  - Specificity: 91.04%  

- âš™ï¸ **Random Forest (caret)**  
  - Accuracy: 71%  
  - Sensitivity: 86.57%  
  - Specificity: 39.39%  

- ğŸ¤– **SVM**  
  - Accuracy: 74%  
  - Sensitivity: 89.55%  
  - Specificity: 42.42%  

---

## ğŸ“ Conclusions
- âœ… **Random Forest (caret):** best sensitivity â†’ useful when detecting defaulters is the priority.  
- âœ… **Base Random Forest:** better balance between accuracy and specificity â†’ reliable in practice.  
- âŒ **Decision Tree:** interpretable but lower performance.  
- âš–ï¸ **SVM:** good overall accuracy but low specificity, limiting its usefulness for credit risk detection.  

---

## ğŸ“Œ Reference
Full analysis published on **RPubs** ğŸ‘‰ [Credit Risk Report](https://rpubs.com/Datamanz/CreditRisk)  

---

## âš–ï¸ License
MIT License Â© 2025 â€” Datamanz
